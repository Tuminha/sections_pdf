# In this file we will only extract the results from the pdf extraction based on the xml file generated by grobid. 
import subprocess
import time
import os
import requests
import xml.etree.ElementTree as ET

# Path to the GROBID service
grobid_path = '/Users/franciscoteixeirabarbosa/projects/test/sections_pdf/grobid'


# First check if the GROBID service is already running, and if it already running do not start it again
# Check if the GROBID service is already running
try:
    response = requests.get('http://localhost:8070/api/isalive')
    if response.status_code == 200:
        print("GROBID service is already running.")
    else:
        # Start the GROBID service
        p = subprocess.Popen(['./gradlew', 'run', '--stacktrace'], cwd=grobid_path)
        # Wait for the GROBID service to start
        time.sleep(10)
except requests.exceptions.RequestException as e:
    # If the request fails, it means the service is not running
    print("GROBID service is not running. Starting it now...")
    p = subprocess.Popen(['./gradlew', 'run', '--stacktrace'], cwd=grobid_path)
    # Wait for the GROBID service to start
    time.sleep(10)

# Wait for the GROBID service to start
time.sleep(10)

pdf_path = '/Users/franciscoteixeirabarbosa/projects/test/sections_pdf/data/Impact_of_Physical_Chemical_Characterist.pdf'

# Send the PDF to GROBID
with open(pdf_path, 'rb') as f:
    response = requests.post('http://localhost:8070/api/processFulltextDocument', files={'input': f})

# Save the XML output
with open('output.xml', 'w') as f:
    f.write(response.text)

# Parse the XML output
tree = ET.parse('output.xml')
root = tree.getroot()

# Define the namespace
ns = {'tei': 'http://www.tei-c.org/ns/1.0'}

# Parse the XML file
tree = ET.parse('output.xml')
root = tree.getroot()

def extract_results(xml_root, namespace):
    # Flag to indicate whether we are in the 'results' section
    in_results = False

    # Find all 'div' elements in the XML
    for div in xml_root.findall('.//tei:div', namespace):
        # Get the title of the section
        title = div.find('tei:head', ns)
        if title is not None:
            title = title.text.strip().lower()  # Remove leading/trailing whitespace and convert to lower case

            # Check if the title contains 'results'
            if 'results' in title:
                print('Results section found:\n')
                in_results = True

            # If we are in the 'results' section and encounter a 'div' with 'discussion' or 'conclusion' in the title, stop printing
            if in_results and ('discussion' in title or 'conclusion' in title):
                break

        if in_results:
            # Recursively find all 'p' elements in the 'div'
            paragraphs = div.findall('.//tei:p', ns)
            for paragraph in paragraphs:
                if paragraph is not None and paragraph.text:  # Check if the paragraph exists and has text
                    print(paragraph.text)  # Print the paragraph text

def extract_tables(xml_root, namespace):
    # Find all 'figure' elements in the XML
    for figure in xml_root.findall('.//tei:figure', namespace):
        table = figure.find('.//tei:table', ns)
        if table is not None:
            print("\nTable:")
            rows = table.findall('.//tei:row', ns)
            for row in rows:
                cells = [cell.text for cell in row.findall('.//tei:cell', ns) if cell.text]
                print('\t'.join(cells))

# Call the functions
extract_results(root, ns)
extract_tables(root, ns)